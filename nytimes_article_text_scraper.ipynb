{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from time import sleep\n",
    "import random \n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['story-body-text story-content','css-c65vdd e2kc3sl0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to grab article body text\n",
    "def get_text(url, class_name):\n",
    "    url = url\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    search_page = response.text\n",
    "    soup = BeautifulSoup(search_page,\"html5lib\")\n",
    "    paragraphs = soup.find_all(class_=class_name)\n",
    "    text = ''\n",
    "    for i in range(len(paragraphs)):\n",
    "        text+=\" \" + paragraphs[i].text\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape articles before 2014\n",
    "links_bcss = pd.read_csv('nytimes_meta_text_1985_2013.csv')\n",
    "links_bcss['article_text'] = [get_text(url,class_names[0]) for url in links_bcss['url']]\n",
    "# links_bcss.to_csv('nytimes_meta_text_1985_2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape articles from 2014 when NYTimes started using new CSS layout\n",
    "links_acss = pd.read_csv('nytimes_meta_text_2014_2018.csv')\n",
    "links_acss['article_text'] = [get_text(url,class_names[0]) for url in links_acss['url']]\n",
    "# links_acss.to_csv('nytimes_meta_text_2014_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last sweep \n",
    "links_bcss_2 = pd.read_csv('nytimes_meta_text_2014_2018_bcss.csv')\n",
    "links_bcss_2['article_text'] = [get_text_1(url) for url in links_bcss_2['url']]\n",
    "# links_bcss_2.to_csv('nytimes_meta_text_2014_2018_bcss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('nytimes_meta_text_1985_2013.csv', encoding='ISO-8859-1')\n",
    "df2 = pd.read_csv('nytimes_meta_text_2014_2018.csv', encoding='ISO-8859-1')\n",
    "df3 = pd.read_csv('nytimes_meta_text_2014_2018_bcss.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [df1, df2, df3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3901"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('nytimes_text_1983_2018.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
