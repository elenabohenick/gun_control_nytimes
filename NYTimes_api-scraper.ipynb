{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from time import sleep\n",
    "import random \n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use beatufull soup to get the number of articles per year\n",
    "One of the parameters for NYTimes API request is 'page'. Page number has to be less than 200 => Need to break down by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(1985,2019,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that inouts a year in the url and return the number of articles with a gives search query\n",
    "def num_of_pages(year):\n",
    "    url = f'https://www.nytimes.com/search/gun%20control/newest/{year}0101/{year}1231'\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    search_page = response.text\n",
    "    soup = BeautifulSoup(search_page,\"html5lib\")\n",
    "    search_result = soup.find_all(class_='SearchForm-searchStatus--2Z3Tw')\n",
    "    search_result_str = str(search_result)\n",
    "    num_of_articles = re.match(r'.*Showing\\s(\\d,*\\d+)\\sresults.*',search_result_str).group(1)\n",
    "    num = int(num_of_articles.replace(',',''))\n",
    "    return(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "news_per_year = defaultdict()\n",
    "for year in years:\n",
    "    news_per_year[year]=num_of_pages(year)\n",
    "    print(year, ': ', num_of_pages(year))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to NYTimes API to get article meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_ROOT = 'https://api.nytimes.com/svc/search/v2/articlesearch.json'\n",
    "\n",
    "API_SIGNUP_PAGE = 'http://developer.nytimes.com/docs/reference/keys'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['*my_key*_here*']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from 01/01/1985 to date there are 19,294 articles that came up for 'gun control' search term.\n",
    "it means i have to iterate through 1930 pages to collect the urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that calls NYTimes API and returns a json object with sesarch page results \n",
    "# Note: returns meta data about 10 articles (1 search page)\n",
    "def create_request(start_date, end_date, page_num):\n",
    "    s = len(keys)-1\n",
    "    API_KEY = keys[random.randint(0,s)]\n",
    "    resp = requests.get(API_ROOT, params={\n",
    "        'api-key': API_KEY,\n",
    "        'q': \"gun control\",\n",
    "        'begin_date': start_date,\n",
    "        'end_date': end_date,\n",
    "        'sort': \"newest\",\n",
    "        'page': page_num})\n",
    "    return(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = create_request('20130101', '20131231', 20)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that takes json output and parses data from it\n",
    "# this will return article URLs for further scraping of articles' text\n",
    "def parse_search_res(json_file):\n",
    "    news = []\n",
    "    for i in json_file['response']['docs']:   \n",
    "        dic = {}\n",
    "        dic['id'] = i['_id']\n",
    "        dic['headline'] = i['headline']['main'].encode(\"utf8\")\n",
    "        dic['date'] = i['pub_date'][0:10]\n",
    "        dic['score'] = i['score']\n",
    "        if i['snippet'] is not None:\n",
    "            dic['snippet'] = i['snippet'].encode(\"utf8\")\n",
    "        if 'source' in i:\n",
    "            dic['source'] = i['source']\n",
    "        if 'type_of_material' in i:\n",
    "            dic['type'] = i['type_of_material']\n",
    "        dic['url'] = i['web_url']\n",
    "        dic['word_count'] = i['word_count']\n",
    "        news.append(dic)\n",
    "    return(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code below with crate take start/end year and output the result with meta-data for all articles \n",
    "# sattisfiying query result published during the set timeframe\n",
    "for k, v in news_per_year.items():\n",
    "    data = []\n",
    "    start_date = f'{k}0101'\n",
    "    end_date = f'{k}1231'\n",
    "    pages = math.ceil(v/10)+1\n",
    "    for page in range(pages):\n",
    "        data.extend(parse_search_res(create_request(start_date,end_date,page)))\n",
    "        sleep(2)\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    df.to_csv(f'nytimes_meta_{k}.csv')\n",
    "    print('Collected:', k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
